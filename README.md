# ğŸ§  Synthetic BigPatent Similarity

Ce projet explore la **similaritÃ© sÃ©mantique de triplets textuels** (ancre, positif, nÃ©gatif) sur un jeu de donnÃ©es inspirÃ© de **BigPatent**. L'objectif est d'entraÃ®ner un modÃ¨le Ã  distinguer si deux textes techniques sont proches en sens, dans un contexte de classification ou de recherche de brevets.

## ğŸ“Œ Objectif

Utiliser un modÃ¨le `SentenceTransformer` pour apprendre une **fonction d'encodage** de textes techniques. Lâ€™entraÃ®nement repose sur une **loss de type triplet**, oÃ¹ le modÃ¨le apprend Ã  rapprocher sÃ©mantiquement un texte "positif" de lâ€™ancre, tout en Ã©loignant un "nÃ©gatif".

## ğŸ§° Outils & Technologies

- `Python 3.10+`
- `Hugging Face Datasets`
- `Sentence Transformers`
- `PyTorch`
- `W&B` pour le suivi des expÃ©riences

## ğŸ—‚ Structure du dataset

Le jeu de donnÃ©es est structurÃ© en triplets :
- `queery`: la requÃªte ou le document de base
- `positive`: un document sÃ©mantiquement proche
- `negative`: un document sans lien sÃ©mantique direct

Le dataset est dÃ©coupÃ© en trois splits : `train`, `valid`, `test`.

## ğŸ” EntraÃ®nement

Le modÃ¨le est fine-tunÃ© avec la `TripletLoss`, combinÃ© Ã  un `TripletEvaluator` basÃ© sur la similaritÃ© cosinus.  
Un modÃ¨le prÃ©-entraÃ®nÃ© lÃ©ger (`GIST-small`) est utilisÃ© comme base.

## âš™ï¸ ParamÃ¨tres d'entraÃ®nement

```python
{
  "num_train_epochs": 10,
  "per_device_train_batch_size": 16,
  "per_device_eval_batch_size": 10,
  "learning_rate": 1e-5,
}
